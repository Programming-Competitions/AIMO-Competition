{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":73231,"databundleVersionId":8133715,"sourceType":"competition"},{"sourceId":7369493,"sourceType":"datasetVersion","datasetId":4281572},{"sourceId":8012825,"sourceType":"datasetVersion","datasetId":4720595},{"sourceId":8023365,"sourceType":"datasetVersion","datasetId":4728129},{"sourceId":5112,"sourceType":"modelInstanceVersion","modelInstanceId":3900},{"sourceId":5994,"sourceType":"modelInstanceVersion","modelInstanceId":4761},{"sourceId":11382,"sourceType":"modelInstanceVersion","modelInstanceId":8318},{"sourceId":11394,"sourceType":"modelInstanceVersion","modelInstanceId":8332}],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":724.728315,"end_time":"2024-02-29T09:37:08.760349","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-29T09:25:04.032034","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"21267b653022419eb6fc3f47aa4db8ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926e7ccdad6440be85c76931860b744c","placeholder":"​","style":"IPY_MODEL_feef8334edb24f6da22e8bb1d8d80c67","value":"Loading checkpoint shards: 100%"}},"2144e851698b4707ad1c7fc29fe21b03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3963993becfa487c9ff725f211915e67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7a725e1b0cc4ad78a62beab5f663065","placeholder":"​","style":"IPY_MODEL_fdb32baaed7145d8a8024b615ef242ca","value":" 19/19 [10:48&lt;00:00, 33.24s/it]"}},"5882b6e860be4a0db012a64fc0704a3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21267b653022419eb6fc3f47aa4db8ed","IPY_MODEL_d91eb83d016a4381828192a98f798f9b","IPY_MODEL_3963993becfa487c9ff725f211915e67"],"layout":"IPY_MODEL_6a892a5561f742bb9db9f13859c18e90"}},"6a892a5561f742bb9db9f13859c18e90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"926e7ccdad6440be85c76931860b744c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d91eb83d016a4381828192a98f798f9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2144e851698b4707ad1c7fc29fe21b03","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0693b32889c42b18b9a3844e045d048","value":19}},"e0693b32889c42b18b9a3844e045d048":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7a725e1b0cc4ad78a62beab5f663065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdb32baaed7145d8a8024b615ef242ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"feef8334edb24f6da22e8bb1d8d80c67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Thank you to https://www.kaggle.com/code/quan0095/more-diversity-in-output-improve-score","metadata":{}},{"cell_type":"code","source":"# credits:\n# https://www.kaggle.com/code/olyatsimboy/aimo-openmath-mistral-baseline\n# https://www.kaggle.com/code/aatiffraz/prompt-prediction-w-mixtral-mistral7b-gemma-llama\n# https://www.kaggle.com/code/thedrcat/aimo-mixtral-baseline","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:44:35.370565Z","iopub.execute_input":"2024-04-04T13:44:35.370923Z","iopub.status.idle":"2024-04-04T13:44:35.376016Z","shell.execute_reply.started":"2024-04-04T13:44:35.370892Z","shell.execute_reply":"2024-04-04T13:44:35.37498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Zero-shot MMOS-DeepSeekMath-7B with self-consistency and generated code reasoning evaluation\n\nSelf-consistency is a modification of the standard greedy decoding in reasoning pipelines via sampling several diverse answers followed by aggregation, e.g., most common answer ([SC-CoT paper](https://arxiv.org/pdf/2203.11171.pdf)).\n\nIn this kernel, we will consider MMOS-DeepSeekMath-7B RL-tuned backbone; in my experiments, this model produces more consistent code reasoning and the code block execution will allow us to decrease arithmetic hallucinations.","metadata":{}},{"cell_type":"code","source":"!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq","metadata":{"papermill":{"duration":18.075198,"end_time":"2024-02-29T09:25:25.295954","exception":false,"start_time":"2024-02-29T09:25:07.220756","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-04T13:44:35.390481Z","iopub.execute_input":"2024-04-04T13:44:35.390945Z","iopub.status.idle":"2024-04-04T13:45:12.245181Z","shell.execute_reply.started":"2024-04-04T13:44:35.390921Z","shell.execute_reply":"2024-04-04T13:45:12.244023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer, \n    BitsAndBytesConfig, \n    AutoConfig,\n    set_seed\n)\n\nset_seed(42)\n\nMODEL_PATH = \"/kaggle/input/deepseek-math\"\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n)\n\nconfig = AutoConfig.from_pretrained(MODEL_PATH)\nconfig.gradient_checkpointing = True\n\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_PATH,\n    device_map=\"auto\",\n    torch_dtype=\"auto\",\n    trust_remote_code=True,\n#     quantization_config=quantization_config,\n    config=config\n)","metadata":{"papermill":{"duration":664.688061,"end_time":"2024-02-29T09:36:29.988515","exception":false,"start_time":"2024-02-29T09:25:25.300454","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-04T12:37:08.095511Z","iopub.execute_input":"2024-04-04T12:37:08.095821Z","iopub.status.idle":"2024-04-04T12:40:25.502135Z","shell.execute_reply.started":"2024-04-04T12:37:08.095794Z","shell.execute_reply":"2024-04-04T12:40:25.501351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.dtype","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:40:25.504773Z","iopub.execute_input":"2024-04-04T12:40:25.505616Z","iopub.status.idle":"2024-04-04T12:40:25.511817Z","shell.execute_reply.started":"2024-04-04T12:40:25.505588Z","shell.execute_reply":"2024-04-04T12:40:25.510912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\nPRIVATE = True\n\ndf = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/test.csv')\ndf.head()","metadata":{"papermill":{"duration":1.224774,"end_time":"2024-02-29T09:36:31.21757","exception":false,"start_time":"2024-02-29T09:36:29.992796","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-04T12:40:25.513103Z","iopub.execute_input":"2024-04-04T12:40:25.513521Z","iopub.status.idle":"2024-04-04T12:40:26.581977Z","shell.execute_reply.started":"2024-04-04T12:40:25.513491Z","shell.execute_reply":"2024-04-04T12:40:26.581011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(df) < 5:\n    df = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/train.csv')\n    PRIVATE = False\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:40:26.583227Z","iopub.execute_input":"2024-04-04T12:40:26.583508Z","iopub.status.idle":"2024-04-04T12:40:26.597283Z","shell.execute_reply.started":"2024-04-04T12:40:26.583484Z","shell.execute_reply":"2024-04-04T12:40:26.596478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndevice = 'cuda'","metadata":{"papermill":{"duration":0.022605,"end_time":"2024-02-29T09:36:31.265878","exception":false,"start_time":"2024-02-29T09:36:31.243273","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-04T12:40:26.598214Z","iopub.execute_input":"2024-04-04T12:40:26.598483Z","iopub.status.idle":"2024-04-04T12:40:26.602053Z","shell.execute_reply.started":"2024-04-04T12:40:26.59846Z","shell.execute_reply":"2024-04-04T12:40:26.60119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def naive_parse(answer):\n    out = []\n    start = False\n    end = False\n    for l in reversed(list(answer)):\n        if l in '0123456789' and not end:\n            start = True\n            out.append(l)\n        else:\n            if start:\n                end = True\n        \n    out = reversed(out)\n    return ''.join(out)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:40:26.603124Z","iopub.execute_input":"2024-04-04T12:40:26.603379Z","iopub.status.idle":"2024-04-04T12:40:26.611697Z","shell.execute_reply.started":"2024-04-04T12:40:26.603357Z","shell.execute_reply":"2024-04-04T12:40:26.61084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype='auto',\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:40:26.612713Z","iopub.execute_input":"2024-04-04T12:40:26.613019Z","iopub.status.idle":"2024-04-04T12:40:40.822465Z","shell.execute_reply.started":"2024-04-04T12:40:26.612995Z","shell.execute_reply":"2024-04-04T12:40:40.821619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Transformers Version: {transformers.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:40:40.825482Z","iopub.execute_input":"2024-04-04T12:40:40.826082Z","iopub.status.idle":"2024-04-04T12:40:40.831016Z","shell.execute_reply.started":"2024-04-04T12:40:40.826054Z","shell.execute_reply":"2024-04-04T12:40:40.829919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:40:40.832244Z","iopub.execute_input":"2024-04-04T12:40:40.832558Z","iopub.status.idle":"2024-04-04T12:40:40.859753Z","shell.execute_reply.started":"2024-04-04T12:40:40.83253Z","shell.execute_reply":"2024-04-04T12:40:40.858801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport sys\nimport subprocess\n\n\ndef process_output(output):\n    result = output\n    \n    try:\n        code = output.split('```')[1][7:]\n\n        with open('code.py', 'w') as fout:\n            fout.write(code)\n\n        batcmd = 'timeout 7 ' + sys.executable + ' code.py'\n        try:\n            shell_output = subprocess.check_output(batcmd, shell=True).decode('utf8')\n            print(shell_output)\n            code_output = round(float(eval(shell_output))) % 1000\n        except:\n            code_output = -1\n\n        print('CODE RESULTS', code_output)\n    \n    except Exception as e:\n        print(e)\n        print('ERROR PARSING')\n        code_output = -1\n    \n    try:\n        result_output = re.findall(r'\\\\boxed\\{(.*)\\}', result)\n\n        print('BOXED', result_output)\n        if not len(result_output):\n            result_output = naive_parse(result)\n        else:\n            result_output = result_output[-1]\n\n        print('BOXED', result_output)\n        if not len(result_output):\n            result_output = -1\n        \n        else:\n            result_output = round(float(eval(result_output))) % 1000\n    \n    except Exception as e:\n        print(e)\n        print('ERROR PARSING')\n        result_output = -1\n    \n    return result_output, code_output","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:40:40.861109Z","iopub.execute_input":"2024-04-04T12:40:40.861474Z","iopub.status.idle":"2024-04-04T12:40:40.873038Z","shell.execute_reply.started":"2024-04-04T12:40:40.861437Z","shell.execute_reply":"2024-04-04T12:40:40.87211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def toMin(s   ):\n     res = s   \n     if ('hours and' in s ):\n       if ('minutes' in s[s.index('hours and'): ]):  \n         if s.index('minutes',s.index('hours and'))-s.index('hours and') == 13:  \n           res =  s[0:s.index('hours and')-3]+ ' '+ str(int(s[s.index('hours and')-3:s.index('hours and')])*60  + int(s[s.index('hours and')-2+12:s.index('hours and')+12]))+ ' '+ s[s.index('minutes',s.index('hours and')): ] \n         if s.index('minutes',s.index('hours and'))-s.index('hours and') == 12:  \n           res =  s[0:s.index('hours and')-3]+ ' '+ str(int(s[s.index('hours and')-3:s.index('hours and')])*60  + int(s[s.index('hours and')-2+12:s.index('hours and')+12]))+ ' '+ s[s.index('minutes',s.index('hours and')): ] \n     return res \ndef toMin_Many(s   ):\n    s_old = s\n    s_new = toMin(s_old )\n    while 1==1:\n        if s_old == s_new:\n            break\n        else:\n           s_old = s_new\n           s_new = toMin(s_old ) \n    s  = s_new\n    return s","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom collections import defaultdict\n\n\ntool_instruction = \" The answer should be given as a non-negative modulo 1000.\"\ntool_instruction += '\\nPlease integrate natural language reasoning with programs to solve the problem above, and put your final answer within \\\\boxed{}.'\n\n\nn_repetitions = 5 if PRIVATE else 2\n\ntotal_results = []\ntotal_answers = []\n\nfor i in tqdm(range(len(df))):\n    id_ = df['id'].loc[i]\n    problem = df['problem'].loc[i]\n    problem = toMin_Many(problem   )\n    messages = [\n        {\n            \"role\": \"user\", \n            \"content\": problem + tool_instruction\n        }\n    ]\n    \n    query_prompt = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False\n    )\n    \n    results = []\n    answers = []\n    \n    for _ in tqdm(range(n_repetitions)):\n        try:\n            raw_output = pipeline(\n                query_prompt, \n                max_new_tokens=2048, \n                do_sample=True, \n                temperature=0.9,\n                return_full_text=False\n            )\n            raw_output = raw_output[0]['generated_text']\n\n            result_output, code_output = process_output(raw_output)\n\n            torch.cuda.empty_cache()\n            gc.collect()\n\n        except Exception as e:\n            print(e)\n            result_output, code_output = -1, -1\n        \n        results.append(result_output)\n        answers.append(code_output)\n    \n    total_results.append(results)\n    total_answers.append(answers)","metadata":{"papermill":{"duration":34.259365,"end_time":"2024-02-29T09:37:05.548829","exception":false,"start_time":"2024-02-29T09:36:31.289464","status":"completed"},"tags":[],"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-04-04T12:45:19.952503Z","iopub.execute_input":"2024-04-04T12:45:19.953336Z","iopub.status.idle":"2024-04-04T13:12:39.919924Z","shell.execute_reply.started":"2024-04-04T12:45:19.953302Z","shell.execute_reply":"2024-04-04T13:12:39.918812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\n\nfinal_answers = []\n\nfor a, b in zip(total_answers, total_results):\n    a = np.array(a)\n    b = np.array(b)\n    a[a < 0] = b[a < 0]\n    \n    pred = Counter(a.tolist()).most_common(2)\n\n    ans = pred[0][0] if not pred[0][0] < 0 else pred[1][0]\n\n    final_answers.append(ans)\n    print(ans)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:12:39.92153Z","iopub.execute_input":"2024-04-04T13:12:39.921821Z","iopub.status.idle":"2024-04-04T13:12:39.928973Z","shell.execute_reply.started":"2024-04-04T13:12:39.921795Z","shell.execute_reply":"2024-04-04T13:12:39.928093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['answer'] = final_answers","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:12:39.930115Z","iopub.execute_input":"2024-04-04T13:12:39.930442Z","iopub.status.idle":"2024-04-04T13:12:39.942032Z","shell.execute_reply.started":"2024-04-04T13:12:39.930409Z","shell.execute_reply":"2024-04-04T13:12:39.941187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:12:39.943956Z","iopub.execute_input":"2024-04-04T13:12:39.944218Z","iopub.status.idle":"2024-04-04T13:12:39.960357Z","shell.execute_reply.started":"2024-04-04T13:12:39.944196Z","shell.execute_reply":"2024-04-04T13:12:39.959337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['id','answer']].to_csv(\"submission.csv\", header=True, index=False)","metadata":{"papermill":{"duration":0.021128,"end_time":"2024-02-29T09:37:05.574782","exception":false,"start_time":"2024-02-29T09:37:05.553654","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-04T13:12:39.961513Z","iopub.execute_input":"2024-04-04T13:12:39.961884Z","iopub.status.idle":"2024-04-04T13:12:39.984974Z","shell.execute_reply.started":"2024-04-04T13:12:39.96183Z","shell.execute_reply":"2024-04-04T13:12:39.984163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['id','answer']].head()","metadata":{"papermill":{"duration":0.014339,"end_time":"2024-02-29T09:37:05.594605","exception":false,"start_time":"2024-02-29T09:37:05.580266","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-04T13:12:39.986047Z","iopub.execute_input":"2024-04-04T13:12:39.986376Z","iopub.status.idle":"2024-04-04T13:12:39.996355Z","shell.execute_reply.started":"2024-04-04T13:12:39.986346Z","shell.execute_reply":"2024-04-04T13:12:39.995483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not PRIVATE:\n    df = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/train.csv')\n    df['model_answer'] = final_answers\n    df['match'] = df.answer == df.model_answer\n    print(f'{df.match.sum()} matches in {len(df)} examples')","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:12:39.997483Z","iopub.execute_input":"2024-04-04T13:12:39.997778Z","iopub.status.idle":"2024-04-04T13:12:40.012306Z","shell.execute_reply.started":"2024-04-04T13:12:39.997733Z","shell.execute_reply":"2024-04-04T13:12:40.011372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}